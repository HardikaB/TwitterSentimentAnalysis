{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.sparse as sparse\n",
    "import string\n",
    "import gc\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,make_scorer,roc_auc_score\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from sklearn import preprocessing \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\")\n",
    "import numpy as np\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "\n",
    "from sklearn.metrics.classification import classification_report, accuracy_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import collections, itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def reduce_dimensions(train_dtm, y_train,test_dtm, k=15000):\\n    \"\"\"Reduce dimensionality\"\"\"\\n    ch2 = SelectKBest(chi2, k)\\n    ch2.fit(train_dtm, y_train)\\n    train_dtm = ch2.transform(train_dtm)\\n    test_dtm = ch2.transform(test_dtm)\\n    return train_dtm, test_dtm'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('./../clean_train_data.csv',index_col='id',encoding='utf-8')\n",
    "del df['Unnamed: 0']\n",
    "df['Tokenized1'].fillna('a',inplace=True)\n",
    "'''def reduce_dimensions(train_dtm, y_train,test_dtm, k=15000):\n",
    "    \"\"\"Reduce dimensionality\"\"\"\n",
    "    ch2 = SelectKBest(chi2, k)\n",
    "    ch2.fit(train_dtm, y_train)\n",
    "    train_dtm = ch2.transform(train_dtm)\n",
    "    test_dtm = ch2.transform(test_dtm)\n",
    "    return train_dtm, test_dtm'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "df = shuffle(df)\n",
    "X=df.copy().drop(columns=['label'])\n",
    "y=df['label']\n",
    "df['Tokenized1'].fillna('a')\n",
    "\n",
    "####tokenize-TfidfVectorizer\n",
    "tknzr = TweetTokenizer()\n",
    "vect_word = TfidfVectorizer(tokenizer=word_tokenize,max_features=1000, analyzer='word', stop_words='english', ngram_range=(1,2), dtype=np.float32) \n",
    "vect_word.fit(df.Tokenized1)\n",
    "####transform\n",
    "tr_tweetvec=vect_word.transform(df.Tokenized1)\n",
    "####Horizontal stacking\n",
    "train = df[['NoEx','NoHash','ListLength','No_HW0','No_HW1','Positive Score','Negative Score','LexicalPopularity','LCUCF','No_T']]\n",
    "train_features = hstack([tr_tweetvec, csr_matrix(train.loc[train.index,])], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     29720\n",
      "          1       0.83      0.54      0.65      2242\n",
      "\n",
      "avg / total       0.96      0.96      0.96     31962\n",
      "\n",
      "Accuracy Train: 95.95%\n",
      "0.955435337939809\n",
      "[[29466   254]\n",
      " [ 1041  1201]]\n"
     ]
    }
   ],
   "source": [
    "model1 = XGBClassifier()\n",
    "model1.fit(train_features,y)\n",
    "y_pred_train_xgb = cross_val_predict(model1,train_features,y,cv=5)\n",
    "accuracy = accuracy_score(y, y_pred_train_xgb)\n",
    "print(classification_report(y, y_pred_train_xgb))\n",
    "print(\"Accuracy Train: %.2f%%\" % (accuracy * 100.0))\n",
    "print(f1_score(y, y_pred_train_xgb, average='weighted'))\n",
    "print(confusion_matrix(y, y_pred_train_xgb))#50,62,239,1132"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     29720\n",
      "          1       0.82      0.54      0.65      2242\n",
      "\n",
      "avg / total       0.96      0.96      0.96     31962\n",
      "\n",
      "Accuracy Train: 95.94%\n",
      "0.955473623081853\n",
      "[[29450   270]\n",
      " [ 1029  1213]]\n"
     ]
    }
   ],
   "source": [
    "model2 = LogisticRegression(penalty='l1',tol=.31)\n",
    "model2.fit(train_features,y)\n",
    "y_pred_train_LR = cross_val_predict(model2,train_features,y,cv=5)\n",
    "accuracy = accuracy_score(y, y_pred_train_LR)\n",
    "print(classification_report(y, y_pred_train_LR))\n",
    "print(\"Accuracy Train: %.2f%%\" % (accuracy * 100.0))\n",
    "print(f1_score(y, y_pred_train_LR, average='weighted'))\n",
    "print(confusion_matrix(y, y_pred_train_LR))#51,64,185,1094"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svmc = SVC(kernel=\"rbf\")\n",
    "svmc.fit(train_features,y)\n",
    "preds_svmc = cross_val_predict(svmc,train_features,y,cv=5)\n",
    "print(classification_report(y, preds_svmc)) \n",
    "print(\"ACCURACY Train::\", accuracy_score(preds_svmc, y))\n",
    "print(f1_score(y, preds_svmc, average='weighted'))\n",
    "print(confusion_matrix(y, preds_svmc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.99      0.98     29720\n",
      "          1       0.83      0.56      0.67      2242\n",
      "\n",
      "avg / total       0.96      0.96      0.96     31962\n",
      "\n",
      "ACCURACY Train:: 0.9610787810524999\n",
      "0.9574835010540947\n",
      "[[29467   253]\n",
      " [  991  1251]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=9)\n",
    "rf.fit(train_features,y)\n",
    "preds_rf = cross_val_predict(rf,train_features,y,cv=5)\n",
    "print(classification_report(y, preds_rf))\n",
    "print(\"ACCURACY Train::\", accuracy_score(preds_rf, y))\n",
    "print(f1_score(y, preds_rf, average='weighted'))\n",
    "print(confusion_matrix(y, preds_rf))#57,69,185,974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred']=preds_rf[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./../clean_train_data1.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost with parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid1 = {\"max_depth\": [2, 3, 4,5,6,8,9],\n",
    "               \"min_child_weight\": [4, 6, 7, 8,12],\n",
    "               }\n",
    "xgb = XGBClassifier(seed=9)\n",
    "\n",
    "def myXGBoost(X_train, y_train, model, param_grid, KFold=3):\n",
    "     \n",
    "    acc_scorer = make_scorer(accuracy_score)\n",
    "    grid_obj = RandomizedSearchCV(model, param_grid, scoring=acc_scorer,cv=KFold)\n",
    "    grid_obj = grid_obj.fit(X_train, y_train)\n",
    "    best_params=grid_obj.best_params_\n",
    "    return grid_obj,best_params\n",
    "xgbobj1,bestparam1_=myXGBoost(train_features, y, xgb, param_grid1, KFold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bestparam1_)\n",
    "print(xgbobj1)\n",
    "y_pred = cross_val_predict(xgbobj1,train_features,y,cv=5)\n",
    "accuracy=accuracy_score(y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc1 = roc_auc_score(y, y_pred)\n",
    "print(classification_report(y, y_pred))\n",
    "print(f1_score(y, y_pred, average='weighted'))\n",
    "print(confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 1010)\n",
      "(31962, 1011)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     29720\n",
      "          1       0.99      0.93      0.96      2242\n",
      "\n",
      "avg / total       0.99      0.99      0.99     31962\n",
      "\n",
      "ACCURACY Train:: 0.99443088667793\n",
      "0.9943378080349047\n",
      "[[29709    11]\n",
      " [  167  2075]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "model = [model2, rf]\n",
    "# Write your code here\n",
    "def stacking_clf(model, X_train, y_train):\n",
    "    voting_clf_hard = VotingClassifier(estimators = [('Logistic Regression', model[0]),('Random Forest 1', model[1])],voting = 'soft')\n",
    "    voting_clf_hard.fit(X_train, y_train)\n",
    "    y_pred_hard = voting_clf_hard.predict(X_train)\n",
    "    print(X_train.shape)\n",
    "    y_pred_hard_DF=pd.DataFrame(y_pred_hard[:,])\n",
    "    X_trainN = hstack([train_features, csr_matrix(y_pred_hard_DF)], 'csr')\n",
    "    print(X_trainN.shape)\n",
    "    stacking_clf1 = StackingClassifier(classifiers = model,meta_classifier = LogisticRegression(random_state=9))\n",
    "    stacking_clf1.fit(X_trainN, y_train)\n",
    "    preds_stacking = stacking_clf1.predict(X_trainN)##cross_val_predict(stacking_clf1,X_trainN, y_train,cv=5)\n",
    "    print(classification_report(y_train, preds_stacking))\n",
    "    print(\"ACCURACY Train::\", accuracy_score(preds_stacking, y_train))\n",
    "    print(f1_score(y_train, preds_stacking, average='weighted'))\n",
    "    print(confusion_matrix(y_train, preds_stacking))\n",
    "    return voting_clf_hard,stacking_clf1\n",
    "voting_clf_hard,stacking_clf1=stacking_clf(model, train_features,y)#93,96,2,159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeSubmission():\n",
    "    \n",
    "    df_test = pd.read_csv('./../clean_test_data.csv',encoding='utf-8')\n",
    "    del df_test['Unnamed: 0']\n",
    "    df_test['Tokenized1'].fillna('a',inplace=True)\n",
    "    test_tweetvec=vect_word.transform(df_test.Tokenized1)\n",
    "    test = df_test[['NoEx','NoHash','ListLength','No_HW0','No_HW1','Positive Score','Negative Score','LexicalPopularity','LCUCF','No_T']]\n",
    "    test_features = hstack([test_tweetvec, csr_matrix(test.loc[test.index,])], 'csr')\n",
    "\n",
    "    y_pred_hard_test = voting_clf_hard.predict(test_features)\n",
    "    y_pred_hard_test_DF=pd.DataFrame(y_pred_hard_test[:,])\n",
    "    X_testN = hstack([test_features, csr_matrix(y_pred_hard_test_DF)], 'csr')\n",
    "    y_test_pred = stacking_clf1.predict(X_testN)\n",
    "\n",
    "    df_sub = pd.DataFrame(y_test_pred,index=df_test['id'],columns=['label'])\n",
    "\n",
    "    df_sub.to_csv('./../RFSubmission1.csv',encoding='utf-8')\n",
    "writeSubmission()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeSubmission():\n",
    "    df_test = pd.read_csv('./../clean_test_data.csv',encoding='utf-8')\n",
    "    del df_test['Unnamed: 0']\n",
    "    X_test=df_test.copy()\n",
    "    test_tweetvec=vect_word.transform(df_test.Tokenized1)\n",
    "    test = df_test[['NoEx','NoHash','ListLength','No_HW0','No_HW1','Positive Score','Negative Score','LexicalPopularity','LCUCF','No_T']]\n",
    "\n",
    "    test_features = hstack([test_tweetvec, csr_matrix(test.loc[test.index,])], 'csr')\n",
    "    y_test_pred=model2.predict(test_features)\n",
    "\n",
    "    df_sub = pd.DataFrame(y_test_pred,index=df_test['id'],columns=['label'])\n",
    "\n",
    "    df_sub.to_csv('./../RFSubmission1.csv',encoding='utf-8')\n",
    "writeSubmission()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
